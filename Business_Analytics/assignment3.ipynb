{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MGTA 453: Assignment #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework assignment, we will use a project created on GitHub. Your job will be to write code for three functions. These functions will ultimately be executed on our own test data after submission. Your grade will be determined by how well it performs on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your own function that executes a two-sided t-test. The function should receive three parameters: `data_frame`, `column_name`, and `comparison_value`. The first parameter, `data_frame`, should be a Pandas DataFrame containing the data. The second parameter, `column_name`, should be a character string representing the name of the column in `data_frame` that has the data whose mean is of interest in the test. The third parameter, `comparison_value`, is the value associated with the null hypothesis, i.e., the value that we take as the true mean of the population.\n",
    "\n",
    "Once you clone the repo on GitHub, you will find a file called: `code-template.ipynb`\n",
    "\n",
    "Inside this file, you will see the following function declaration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_mean_two_sided(data_frame, column_name, comparison_value):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code in the function body to compute the t-test and return the p-value associated with the test statistic. <u>**DO NOT**</u> use any t-test functions built into `scipy`, `pyrsm`, or any other Python library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your own function that examines a series of draws from varying uniform distributions (i.e., the minimum and maximum values vary: [0,1], [21,30], [5,95], etc.), sums these draws, and then determine the likelihood one would have observed a sum that large. In this function, you must rely on simulation. The function should receive two parameters: `data_frame` and `n_sims`. The first parameter, `data_frame`, should be a Pandas DataFrame containing three columns: `val`, `min`, and `max`. Each row then is a value (`val`) drawn from a uniform distribution with a minimum bound (`min`) and a maximum bound (`max`). The second parameter, `n_sims`, represents the number of times the function will simulate the series of draws for the purposes of determining likelihood. For example `n_sims` being 1,000 means that the comparison distribution will be formed from 1,000 simulated vectors of values giving 1,000 simulated sums to compare against.\n",
    "\n",
    "Inside `code-template.ipynb`, you will see the following function declaration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_sum_one_sided(data_frame, n_sims):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code in the function body to perform a simulation and return the probability of getting a sum greater than or equal to that which is computed from the data passed in as a parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your own function that computes a confidence interval based on the t distribution as well as the bootstrap. The function should receive four parameters: `seed`, `vector_size`, `confidence`, and `bootstrap_sims`. The first parameter, `seed`, simply sets Python's underlying simulator to a state such that the random values that are generated can be easily controlled and compared. The second parameter, `vector_size`, specifies the size of a vector of standard normally distributed random variables you should generate in the code. For example, if `vector_size` is 5, then you should generate a vector of 5 values simulated from the standard normal distribution. The third parameter, `confidence`, specifies the significance level of the confidence intervals you are computing.\n",
    "\n",
    "Inside `code-template.ipynb`, you will see the following function declaration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def confidence_intervals_bootstrap(seed, vector_size, confidence, bootstrap_sims):\n",
    "\n",
    "  np.random.seed(seed)\n",
    "\n",
    "  # code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first part of the code, use the first three parameters to compute the confidence interval for the true **mean** of the population given the (`vector_size`) randomly generated standard normal draws you created. I realize that you know these values are coming from a mean 0 and standard deviation 1, normal distribution, but we are pretending to not know that to better understanding the concept of confidence intervals. Store your confidence interval as a vector with the lower bound being the first column and the upper bound being the second column. For example, you might use `ci` as a variable, in which case printing `ci` would yield something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ci)\n",
    "\n",
    "(-0.4877050, 0.2140357)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second part of the code, you will create confidence intervals on the population mean using a technique known as the bootstrap. In this case, you take the vector of standard normals you already generated in the first part. Then, you will treat those values as the bootstrap “population” and sample from that population with replacement. To build an understanding of this, execute the following code in your Jupyter Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (10, 20, 30, 40, 50, 60)\n",
    "np.random.choice(data, size=len(data), replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just keep running the second line of code above over and over, and you will see it keeps sampling from that population with replacement, which you can see means that it is quite possible to get the same value twice.\n",
    "\n",
    "Continuing on, the idea of the bootstrap is that you will do this many times and for each of these resamples, you will compute the mean. So, if you did this 10,000 times, you would have computed 10,000 means (one for each of the resamples). Now that you have 10,000 means, you can visualize the empirical bootstrap distribution. Just use the `hist()` function available in `matplotlib.pyplot`. Suppose you wanted a 90% confidence interval, then you can find the critical values associated with the 5 and 95 percentiles of the empirical distribution. Those values give you the confidence interval.\n",
    "\n",
    "For the second part of the function, write code that generates a `bootstrap_sims` number of resamples and computes the confidence interval. For example, you might use `ci_boot` as a variable, in which case printing `ci_boot` would yield something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ci_boot)\n",
    "\n",
    "[-0.4681057  0.1920387]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have completed this, the function should return a vector with four values. For example:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return np.concatenate((ci, ci_boot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_mean_two_sided(data_frame, column_name, comparison_value):\n",
    "    data = data_frame[column_name]\n",
    "    n = len(data)\n",
    "    sample_mean = np.mean(data)\n",
    "    sample_std = np.std(data)\n",
    "    t_statistic = (sample_mean - comparison_value) / (sample_std / (n**0.5))\n",
    "    p_value = 2 * (1 - t.cdf(abs(t_statistic), df=n-1)) \n",
    "    return p_val\n",
    "\n",
    "    # insert code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_sum_one_sided(data_frame, n_sims):\n",
    "    random_value = np.random.uniform(data_frame['min'], data_frame['max'], (n_sims, len(data_frame)))\n",
    "    data_sum = data_frame['val'].sum()\n",
    "    xbar = random_value.sum(axis = 1)\n",
    "    return sum(xbar > data_sum)/n_sims\n",
    "    # insert code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_intervals_bootstrap(seed, vector_size, confidence, bootstrap_sims):\n",
    "    np.random.seed(seed)\n",
    "    data = np.random.randn(vector_size)\n",
    "    \n",
    "    # Calculate t-dist based confidence interval\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data, ddof=1) / np.sqrt(vector_size)\n",
    "    t_critical = t.ppf((1 + confidence) / 2, df=vector_size - 1)\n",
    "    mse = t_critical * std\n",
    "    ci = (mean - mse, mean + mse)\n",
    "    \n",
    "        \n",
    "    # Bootstrap confidence interval\n",
    "    bootstrap_means = np.zeros(bootstrap_sims)\n",
    "    \n",
    "    for i in range(bootstrap_sims):\n",
    "        bootstrap_sample = np.random.choice(data, size=vector_size, replace=True)\n",
    "        bootstrap_means[i] = np.mean(bootstrap_sample)\n",
    "    \n",
    "    lower_bound = np.percentile(bootstrap_means, (1 - confidence) / 2 * 100)\n",
    "    upper_bound = np.percentile(bootstrap_means, (1 + confidence) / 2 * 100)\n",
    "    ci_boot = (lower_bound, upper_bound)\n",
    "    \n",
    "    return np.concatenate((ci, ci_boot))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
